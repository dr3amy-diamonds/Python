# ğŸ¼ Pandas â€“ OptimizaciÃ³n de Carga y Lectura de Datos

Este documento contiene una serie de ejercicios conceptuales diseÃ±ados para comprender **cÃ³mo cargar datos de forma eficiente en Pandas**, optimizando memoria, tipos de datos y formatos de almacenamiento.

> âš ï¸ **Nota importante:**  
> Este archivo **NO contiene cÃ³digo resuelto**, Ãºnicamente las consignas, contextos y misiones de cada ejercicio.

---

## ğŸŸ¢ Ejercicio 1: La Dieta de Columnas (`usecols`)

### Contexto
El departamento de IT envÃ­a un log de servidor gigantesco con decenas de columnas tÃ©cnicas irrelevantes.  
Tu jefe solo necesita dos cosas:
- **CuÃ¡ndo ocurriÃ³ el error**
- **QuÃ© mensaje produjo**

### Datos de Entrada
Debes crear un archivo llamado **`log_servidor.csv`** con las siguientes columnas:

- **Fecha**:  
  - 2024-01-01  
  - 2024-01-02  
  - 2024-01-03  

- **IP** (dato irrelevante):  
  - 192.168.1.1  
  - 127.0.0.1  
  - 10.0.0.1  

- **Usuario** (dato irrelevante):  
  - Admin  
  - Guest  
  - Root  

- **Mensaje**:  
  - Error 404  
  - Login OK  
  - Timeout  

### Tu MisiÃ³n
1. Cargar el archivo completo en un DataFrame llamado **`df_gordo`** y medir su uso de memoria.
2. Cargar nuevamente el archivo en **`df_flaco`**, usando `usecols` para traer **solo Fecha y Mensaje**.
3. Comparar el uso de memoria entre ambos.
4. Reflexionar:  
   > Â¿Por quÃ© cargarÃ­as la IP si nadie te la pidiÃ³?

---

## ğŸŸ¡ Ejercicio 2: El Traductor Anticipado (`dtype` & `parse_dates`)

### Contexto
El sistema exporta datos con problemas comunes:
- Los cÃ³digos de sucursal pierden ceros a la izquierda.
- Las fechas llegan como texto.

Debes **corregir esto durante la carga**, no despuÃ©s.

### Datos de Entrada
Crea un archivo llamado **`sucursales.csv`** con:

- **fecha** (texto):
  - 01/01/2024  
  - 02/01/2024  

- **sucursal_id** (texto, conserva ceros):
  - 001  
  - 002  

- **tipo_tienda**:
  - A  
  - B  

### Tu MisiÃ³n
1. Definir un diccionario de tipos (`tipos = {...}`):
   - `sucursal_id` como texto (`object`)
   - `tipo_tienda` como categorÃ­a
2. Usar ese diccionario en el parÃ¡metro `dtype` al cargar el CSV.
3. Usar `parse_dates` para convertir la columna fecha automÃ¡ticamente.
4. Imprimir `.info()` para verificar:
   - `sucursal_id` **no es int**
   - `fecha` es `datetime64`

---

## ğŸŸ  Ejercicio 3: El Desfile de Hormigas (`chunksize`)

### Contexto
Simulas un archivo gigantesco, pero tu memoria solo permite procesar **2 filas a la vez**.  
Debes calcular una suma total sin cargar todo el archivo en memoria.

### Datos de Entrada
Crea un archivo llamado **`mini_bigdata.csv`** con una sola columna:

- **valor**:  
  - NÃºmeros del 1 al 10

### Tu MisiÃ³n
1. Crear un iterador usando `pd.read_csv()` con `chunksize=2`.
2. Inicializar una variable `suma_total = 0`.
3. Recorrer los bloques con un bucle.
4. En cada iteraciÃ³n:
   - Imprimir: *Procesando loteâ€¦*
   - Sumar los valores del bloque.
5. Imprimir el resultado final.

ğŸ“Œ Resultado esperado: **55**

---

## ğŸ”´ Ejercicio 4: La Carrera de Formatos (Pickle vs CSV)

### Contexto
Tu empresa guarda histÃ³ricos diarios en CSV y la lectura tarda horas.  
Quieres demostrar que **Pickle es mÃ¡s rÃ¡pido para Pandas**.

### Datos de Entrada
Usa:
- El DataFrame del Ejercicio 1  
  **o**
- Uno nuevo con datos simples

GuÃ¡rdalo como:
- `datos.csv`
- `datos.pkl`

### Tu MisiÃ³n
1. Importar la librerÃ­a `time`.
2. Medir cuÃ¡nto tarda en cargarse:
   - El archivo CSV
   - El archivo Pickle
3. Comparar los tiempos.
4. Imprimir una frase final:

> **"El formato Pickle fue X segundos mÃ¡s rÃ¡pido que el CSV"**

---

## ğŸ§  Idea Clave Final
Estos ejercicios no tratan de escribir cÃ³digo mÃ¡s corto, sino de **pensar mejor antes de cargar datos**:
- Menos columnas â†’ menos memoria
- Tipos correctos â†’ menos errores
- Procesamiento por partes â†’ escalabilidad
- Formatos adecuados â†’ velocidad

Pandas no es lento.  
Leer mal los datos sÃ­.
