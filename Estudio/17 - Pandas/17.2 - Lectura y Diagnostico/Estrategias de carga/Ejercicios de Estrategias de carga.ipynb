{
 "cells": [
  {
   "cell_type": "code",
   "id": "bc8f939a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:28:27.004514200Z",
     "start_time": "2026-02-10T22:28:26.125561600Z"
    }
   },
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "d7cd81a3",
   "metadata": {},
   "source": [
    "# # Solución 1: La Dieta de Columnas (`usecols`)"
   ]
  },
  {
   "cell_type": "code",
   "id": "6b11f34d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T22:28:27.238313200Z",
     "start_time": "2026-02-10T22:28:27.007271300Z"
    }
   },
   "source": [
    "#1. Creamos el dataframe\n",
    "df_gordo=pd.DataFrame({\n",
    "    'fecha': ['2024-01-01', '2024-01-02', '2024-01-03'] * 15000,\n",
    "    'ip': ['192.168.1.1', '127.0.0.1', '10.0.0.1']* 15000,\n",
    "    'usuario': ['Admin', 'Guest', 'Root'] * 15000,\n",
    "    'mensaje': ['Error 404', 'Login OK', 'Timeout']*15000\n",
    "})\n",
    "\n",
    "#2. Guardamos el archivo\n",
    "df_gordo.to_csv('Archivos/log_servidor.csv', index=False)\n",
    "\n",
    "df_gordo.to_pickle('Archivos/log_servidor.pkl')\n",
    "\n",
    "#3. Medir uso de memoria\n",
    "print(f\"Uso de memoria: {df_gordo.memory_usage(deep=True).sum()} bytes\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uso de memoria: 2880132 bytes\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d991e5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.DataFrame'>\n",
      "DatetimeIndex: 45000 entries, 2024-01-01 to 2024-01-03\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype   \n",
      "---  ------   --------------  -----   \n",
      " 0   mensaje  45000 non-null  category\n",
      "dtypes: category(1)\n",
      "memory usage: 395.6 KB\n",
      "None\n",
      "\n",
      "Observa: El índice ya es Datetime y 'mensaje' es Category.\n"
     ]
    }
   ],
   "source": [
    "#4. Crear una \"deposito\" nuevo para el archivo y extraer solo las columnas 'fecha' y 'mensaje'\n",
    "\n",
    "#Optimizar los datos de las columnas\n",
    "columnas_optimizadas = {\n",
    "    'mensaje' : 'category'  #Optimización de mensajes\n",
    "}\n",
    "df_flaco = pd.read_csv('Archivos/log_servidor.csv',\n",
    "                    usecols=['fecha','mensaje'],  #Filtrado vertical\n",
    "                    dtype=columnas_optimizadas,\n",
    "                    parse_dates=['fecha'],  #Parseo temporal inmediato\n",
    "                    index_col='fecha'\n",
    ")\n",
    "\n",
    "print(df_flaco.info())\n",
    "print(\"\\nObserva: El índice ya es Datetime y 'mensaje' es Category.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f0e20e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_gordo: 2.75 MB\n",
      "df_flaco: 0.39 MB\n"
     ]
    }
   ],
   "source": [
    "#Uso de memoria de bytes a megabytes\n",
    "df_gordo_mb = df_gordo.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "df_flaco_mb = df_flaco.memory_usage(deep=True).sum() / (1024 ** 2)\n",
    "\n",
    "print(f\"df_gordo: {df_gordo_mb:.2f} MB\")\n",
    "print(f\"df_flaco: {df_flaco_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8f56e7",
   "metadata": {},
   "source": [
    "# Solución 2: El Traductor Anticipado (`dtype` & `parse_dates`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3bd371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sucursal = pd.DataFrame ({\n",
    "    'fecha':['2024-01-01','2024-02-01'],\n",
    "    'sucursal_id' :['001','002'],\n",
    "    'tipo_tienda' : ['A','B']\n",
    "})\n",
    "\n",
    "#Crear archivo sucursales.csv\n",
    "df_sucursal.to_csv('Archivos/sucursales.csv', index=False)\n",
    "\n",
    "#Definir tipos\n",
    "tipos = {\n",
    "    'sucursal_id': 'object',    # texto\n",
    "    'tipo_tienda': 'category'   # categoría\n",
    "}\n",
    "\n",
    "#Leer CSV y añadir dtype\n",
    "df_read = pd.read_csv(\n",
    "    'Archivos/sucursales.csv',             # reemplaza con tu ruta\n",
    "    dtype=tipos,               # aplica los tipos del diccionario\n",
    "    parse_dates=['fecha']      # convierte la columna fecha a datetime\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "496a6613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- Información DtaFrame de sucursales----------\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   fecha        2 non-null      datetime64[us]\n",
      " 1   sucursal_id  2 non-null      object        \n",
      " 2   tipo_tienda  2 non-null      category      \n",
      "dtypes: category(1), datetime64[us](1), object(1)\n",
      "memory usage: 184.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Imprimir información\n",
    "print(\"--------- Información DtaFrame de sucursales----------\")\n",
    "print(df_read.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abe8899",
   "metadata": {},
   "source": [
    "# Solución 3: El Desfile de Hormigas (`chunksize`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b90c80b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lote 1: Suma Parcial:3\n",
      "Lote 2: Suma Parcial:7\n",
      "Lote 3: Suma Parcial:11\n",
      "Lote 4: Suma Parcial:15\n",
      "Lote 5: Suma Parcial:19\n",
      "\\Resultado Final:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: SyntaxWarning: \"\\R\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\R\"? A raw string is also an option.\n",
      "<>:18: SyntaxWarning: \"\\R\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\R\"? A raw string is also an option.\n",
      "C:\\Users\\danny\\AppData\\Local\\Temp\\ipykernel_8404\\638930373.py:18: SyntaxWarning: \"\\R\" is an invalid escape sequence. Such sequences will not work in the future. Did you mean \"\\\\R\"? A raw string is also an option.\n",
      "  print(f\"\\Resultado Final:{suma_total}\")\n"
     ]
    }
   ],
   "source": [
    "#Crear DataFrame\n",
    "df_data=pd.DataFrame({\n",
    "    'valores':np.arange(1,11)\n",
    "})\n",
    "\n",
    "#Crear Archivo CSV\n",
    "df_data.to_csv('Archivos/mini_bigdata.csv', index=False)\n",
    "\n",
    "#Crear iterador y chucksize\n",
    "chucksize_data=pd.read_csv(\"Archivos/mini_bigdata.csv\", chunksize=2)\n",
    "suma_total=0\n",
    "for i, lote_mini in enumerate (chucksize_data):\n",
    "    suma_lote=lote_mini[\"valores\"].sum()\n",
    "    suma_total+=suma_lote\n",
    "    print(f\"Lote {i+1}: Suma Parcial:{suma_lote}\")\n",
    "\n",
    "\n",
    "print(f\"\\Resultado Final:{suma_total}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1eb36",
   "metadata": {},
   "source": [
    "# Solución 4: La Carrera de Formatos (Pickle vs CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fc6f3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos Creados exitosamente\n",
      "---------TIEMPO DE carga de archivos-----\n",
      "Tiempo CSV: 0.0043 segundos\n",
      "Tiempo Pickle: 0.0029 segundos\n",
      "Pickle es 1.5 veces más rápido.\n"
     ]
    }
   ],
   "source": [
    "df_person = pd.DataFrame({\n",
    "    \"id\": [1, 2, 3, 4],\n",
    "    \"nombre\": [\"Ana\", \"Luis\", \"María\", \"Juan\"],\n",
    "    \"edad\": [23, 30, 27, 35]\n",
    "})\n",
    "\n",
    "#Crear Archivos csv y pkl\n",
    "try:\n",
    "    df_person.to_csv('Archivos/datos.csv',index=False)\n",
    "    df_person.to_pickle('Archivos/datos.pkl')\n",
    "    print(\"Archivos Creados exitosamente\")\n",
    "except:\n",
    "    print('No se pudo crear los archivos, intente de nuevo')\n",
    "\n",
    "print(\"---------TIEMPO DE carga de archivos-----\")\n",
    "# Iniciar medición de tiempo\n",
    "inicio_csv = time.time()\n",
    "# Cargar el CSV\n",
    "df_time = pd.read_csv('Archivos/datos.csv')\n",
    "fin_csv = time.time()\n",
    "tiempo_csv= fin_csv-inicio_csv\n",
    "print(f\"Tiempo CSV: {tiempo_csv:.4f} segundos\")\n",
    "\n",
    "# Iniciar medición de tiempo\n",
    "inicio_pkl = time.time()\n",
    "# Cargar el CSV\n",
    "df_pkl = pd.read_pickle('Archivos/datos.pkl')\n",
    "fin_pkl = time.time()\n",
    "tiempo_pkl= fin_pkl-inicio_pkl\n",
    "print(f\"Tiempo Pickle: {tiempo_pkl:.4f} segundos\")\n",
    "print(f\"Pickle es {tiempo_csv / tiempo_pkl:.1f} veces más rápido.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0749ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cuanto tarda en cargarse CSV\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
